{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_9기_김혜수_교통표지판분류.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNM7HPvXIXRwuPyh8n1W5L0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyesukim1/German-Load-Sign-Classification/blob/main/%EA%B5%90%ED%86%B5%ED%91%9C%EC%A7%80%ED%8C%90%EB%B6%84%EB%A5%98_%EB%AA%A8%EB%8D%B8%20%EB%B9%84%EA%B5%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "### We should get the data set from Kaggle by using Kaggle API"
      ],
      "metadata": {
        "id": "ocSkM1KWBQdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkcqrJrDeYmM"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle # 케글 데이터 설치\n",
        "\n",
        "# kaggle.json 파일 코렙드라이브로 마운팅하기\n",
        "from google.colab import files \n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 케글 파일 만들기\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Permission Warning 이 일어나지 않도록 \n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ydYu5-i-eoss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 케글 제이슨 파일 제대로 설치 됬는지 확인\n",
        "!ls -lha kaggle.json # kaggle.json 이렇게 뜸\n",
        "\n",
        "! kaggle competitions list"
      ],
      "metadata": {
        "id": "dz2OlUAierjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\\"
      ],
      "metadata": {
        "id": "aOQ7peg_etvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gtsrb-german-traffic-sign.zip # zip 파일 풀기"
      ],
      "metadata": {
        "id": "IpaIIDH-ewu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the packages & Check the data set"
      ],
      "metadata": {
        "id": "hvRbR4ZRBu6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "import cv2 #영상처리에 사용하는 오픈소스 라이브러리, 컴퓨터가 사람 눈처럼 인식할 수 있게 처리\n",
        "from PIL import Image # 파이썬 이미지 처리 pillow 라이브러리\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #imagedatagenerater는 이미지를 학습시킬 때 학습 데이터의 양이 적을 경우 학습데이터를 조금씩 변형 시켜서 학습데이터의 양을 늘리는 방식중 하나\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "style.use('fivethirtyeight')#그래프 스타일 지정\n",
        "\n",
        "#난수 랜덤성 고정\n",
        "np.random.seed(42)\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "K8O4IG-Feygl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 프레임으로 데이터 생김새 확인\n",
        "meta_df = pd.read_csv('Meta.csv')\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "\n",
        "print(meta_df.info())\n",
        "print('====================================')\n",
        "print(train_df.info())\n",
        "print('====================================')\n",
        "print(test_df.info())\n",
        "\n",
        "# Roi는 Region of interest의 약자로 데이터에서 표지판이 있는 부분을 의미"
      ],
      "metadata": {
        "id": "CwarFH5AByr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Roi 데이터를 사용하면 명확하게 표지판 부분만 crop할 수 있고 이러한 데이터 전 처리를 통해 분류의 성능을 높일 수 있음(근데 이번 프로젝트에선 스킵)\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "\n",
        "img_sample = Image.open('/content/'+train_df['Path'][0])\n",
        "\n",
        "draw = ImageDraw.Draw(img_sample)\n",
        "draw.rectangle([train_df['Roi.X1'][1], train_df['Roi.Y1'][1], train_df['Roi.X2'][1], train_df['Roi.Y2'][1]], outline=\"red\")\n",
        "img_sample_resized = img_sample.resize((300,300))\n",
        "img_sample_resized"
      ],
      "metadata": {
        "id": "ZWgnYIH_B0Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코렙은 좌측 파일 아이콘 클릭해서 마운팅된 파일 하나를 오른쪽 마우스 클릭하면 경로 카피할 수 있음 \n",
        "data_dir = pathlib.Path('/content/Meta')\n",
        "train_path = pathlib.Path('/content/Train')\n",
        "test_path = pathlib.Path('/content/Test')"
      ],
      "metadata": {
        "id": "OlMRMCOfCHLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing\n",
        "- Data Transformation: Normalization\n",
        "- Make image data labeling\n",
        "- Cateforical variable: One Hot Encoding\n",
        "- Image size distribution(The size and resolution of images are different) \n",
        "\n",
        "\n",
        "- To normalizing values between 0 and 1 instead of 0 to 255"
      ],
      "metadata": {
        "id": "TOhNrZ4lCsqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 카테고리 수 확인\n",
        "NUM_CATEGORIES = len(os.listdir(train_path))\n",
        "NUM_CATEGORIES"
      ],
      "metadata": {
        "id": "mNsNZF85CsOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 라벨링\n",
        "classes = { 0:'0_Speed limit (20km/h)',\n",
        "            1:'1_Speed limit (30km/h)', \n",
        "            2:'2_Speed limit (50km/h)', \n",
        "            3:'3_Speed limit (60km/h)', \n",
        "            4:'4_Speed limit (70km/h)', \n",
        "            5:'5_Speed limit (80km/h)', \n",
        "            6:'6_End of speed limit (80km/h)', \n",
        "            7:'7_Speed limit (100km/h)', \n",
        "            8:'8_Speed limit (120km/h)', \n",
        "            9:'9_No passing', \n",
        "            10:'10_No passing veh over 3.5 tons', \n",
        "            11:'11_Right-of-way at intersection', \n",
        "            12:'12_Priority road', \n",
        "            13:'13_Yield', \n",
        "            14:'14_Stop', \n",
        "            15:'15_No vehicles', \n",
        "            16:'16_Veh > 3.5 tons prohibited', \n",
        "            17:'17_No entry', \n",
        "            18:'18_General caution', \n",
        "            19:'19_Dangerous curve left', \n",
        "            20:'20_Dangerous curve right', \n",
        "            21:'21_Double curve', \n",
        "            22:'22_Bumpy road', \n",
        "            23:'23_Slippery road', \n",
        "            24:'24_Road narrows on the right', \n",
        "            25:'25_Road work', \n",
        "            26:'26_Traffic signals', \n",
        "            27:'27_Pedestrians', \n",
        "            28:'28_Children crossing', \n",
        "            29:'29_Bicycles crossing', \n",
        "            30:'30_Beware of ice/snow',\n",
        "            31:'31_Wild animals crossing', \n",
        "            32:'32_End speed + passing limits', \n",
        "            33:'33_Turn right ahead', \n",
        "            34:'34_Turn left ahead', \n",
        "            35:'35_Ahead only', \n",
        "            36:'36_Go straight or right', \n",
        "            37:'37_Go straight or left', \n",
        "            38:'38_Keep right', \n",
        "            39:'39_Keep left', \n",
        "            40:'40_Roundabout mandatory', \n",
        "            41:'41_End of no passing', \n",
        "            42:'42_End no passing veh > 3.5 tons' }"
      ],
      "metadata": {
        "id": "XZOaEofcCqrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지별 크기 빈도 확인\n",
        "plt.figure(figsize=(30,10))\n",
        "ax = sns.countplot(x=\"Width\", data=train_df)"
      ],
      "metadata": {
        "id": "_FW-Y-BzD3gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 많은 너비를가지는 이미지를 10단위로 묶어서 확인\n",
        "# 너무 작은 이미지는 큰 이미지의 정보 손실을 발생하며, 너무 큰 이미지는 작은 이미지의 부족한 정보량을 부각 시킬 것\n",
        "df_cutWidth = pd.cut(train_df['Width'], np.arange(0,200,10)).value_counts(sort=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "ax.bar(range(len(df_cutWidth)),df_cutWidth.values)\n",
        "ax.set_xticks(range(len(df_cutWidth)))\n",
        "ax.set_xticklabels(df_cutWidth.index)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KQzR6jCnD5PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리: 이미지 별로 사이즈가 다르기 때문에 이미지의 폭과 높이를 같은 크기로 통일\n",
        "IMG_HEIGHT = 32\n",
        "IMG_WIDTH = 32\n",
        "channels = 3"
      ],
      "metadata": {
        "id": "EYxvDe2aEIJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration & Visualization"
      ],
      "metadata": {
        "id": "ZHqw06wnEdiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 15))\n",
        "for i in range (0,43):\n",
        "    plt.subplot(7,7,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    path = \"/content/Meta/{0}.png\".format(i)\n",
        "    img = plt.imread(path)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(i)"
      ],
      "metadata": {
        "id": "JcM6ImFNj-Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 교통표시판 시각화\n",
        "# pathlib모듈을 사용하면, 파일, 디렉토리(폴더)의 경로를 객체로써 조작하거나 처리할 수 있다\n",
        "\n",
        "img_dir = pathlib.Path('/content/train')\n",
        "plt.figure(figsize=(30,30))\n",
        "index = 0\n",
        "for i in range(NUM_CATEGORIES):\n",
        "    plt.subplot(7, 7, i+1)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([]) #눈금 설정 없음\n",
        "    plt.yticks([])\n",
        "    sign = list(img_dir.glob(f'{i}/*'))[0] #glob모듈의 glob함수는 사용자가 제시한 조건에 맞는 파일명을 리스트형식으로 반환 #*(아스터리스크)는 임의 길이의 모든 문자열을 의미\n",
        "    img = load_img(sign, target_size=(40, 40))\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cw4ZHxDLEVk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = os.listdir('/content/train') #os.listdir() 매써드는 지정한 디렉토리 내의 모든 파일과 디렉토리 리스트(list)를 리턴\n",
        "\n",
        "train_num = []\n",
        "class_num = []\n",
        "\n",
        "for folder in folders:\n",
        "  train_files = os.listdir(str(train_path) + '/'+ folder) #리스트로 가져오면 에러떠서 str로 변환해줌\n",
        "  train_num.append(len(train_files))\n",
        "  class_num.append(classes[int(folder)])\n",
        "\n",
        "# 각각의 클래스의 이미지의 수에 기초해 데이터셋 분류하기\n",
        "zipped_lists =  zip(train_num, class_num)\n",
        "sorted_pairs = sorted(zipped_lists)\n",
        "tuples =  zip(*sorted_pairs) # sorted(정렬할 데이터), 새로운 정렬된 리스트로 만들어서 반환\n",
        "train_num, class_num = [ list(tuple) for tuple in tuples]\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize = (21, 10))\n",
        "plt.bar(class_num, train_num)\n",
        "plt.xticks(class_num, rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_UvPzTcFEUq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discover dataset balance\n",
        "fig, axs = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(25, 6))\n",
        "axs[0].set_title('Train classes distribution')\n",
        "axs[0].set_xlabel('Class')\n",
        "axs[0].set_ylabel('Count')\n",
        "axs[1].set_title('Test classes distribution')\n",
        "axs[1].set_xlabel('Class')\n",
        "axs[1].set_ylabel('Count')\n",
        "\n",
        "sns.countplot(train_df.ClassId, ax=axs[0],  order = train_df['ClassId'].value_counts(ascending=True).index, palette=\"Blues\")\n",
        "sns.countplot(test_df.ClassId, ax=axs[1], order = test_df['ClassId'].value_counts(ascending=True).index, palette=\"Blues\")\n",
        "axs[0].set_xlabel('Class ID');\n",
        "axs[1].set_xlabel('Class ID');\n",
        "\n",
        "# Train and Test subset of dataset have similar balance distribution."
      ],
      "metadata": {
        "id": "bvMFjLEpGlzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 모델"
      ],
      "metadata": {
        "id": "nOVdhvdPSMxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir):\n",
        "    images = list()\n",
        "    labels = list()\n",
        "    for category in range(NUM_CATEGORIES):\n",
        "        categories = os.path.join(data_dir, str(category))\n",
        "        for img in os.listdir(categories):\n",
        "            img = load_img(os.path.join(categories, img), target_size=(32, 32))\n",
        "            image = img_to_array(img) # 이미지를 넘파이 배열로 변환\n",
        "            images.append(image) \n",
        "            labels.append(category)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "images, labels = load_data(train_path)\n",
        "\n",
        "image_data = np.array(images)\n",
        "image_labels = np.array(labels)"
      ],
      "metadata": {
        "id": "3UDSU_XyEQup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 트레인, 테스트 셋 데이터 나누기\n",
        "x_train, x_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.3, random_state=42, shuffle=True)\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "s5pjiWEmGunQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.4)\n",
        "# x_train = x_train.astype('float32')/255 \n",
        "# x_val = x_val.astype('float32')/255\n",
        "# y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
        "# y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)"
      ],
      "metadata": {
        "id": "d3JCMyMCHJvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터의 픽셀정보를 0~1.0사이의 값으로 가지게 만들기, 로컬 미니멈 빠지지 않도록\n",
        "x_train = x_train.astype('float32')/255 \n",
        "x_val = x_val.astype('float32')/255\n",
        "\n",
        "# 라벨에 원핫 인코딩 적용\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
        "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "rgT_vZKnHXUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이스 모델 작성_기본적인 cnn 모델\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 첫번째 Convolutional Layer : 입력 데이터로부터 특징을 추출\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,3)))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "# 두번째 Convolutional Layer\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25)) # 인풋데이터의 25%를 무작위로 0으로 만듦\n",
        "\n",
        "# 세번째 Convolutional Layer\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu')) # 특징을 추출하는 기능을 하는 필터, 비선형 값으로 바꿔주는 activation 함수->relu\n",
        "\n",
        "# Flattening the layer and adding Dense Layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(NUM_CATEGORIES, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tIFEU57pGnSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([    \n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    \n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    \n",
        "    keras.layers.Dense(43, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "ivP8KdVWiPy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "# model.compile(\n",
        "#     loss='categorical_crossentropy', # 다중분류의 로스 함수\n",
        "#     optimizer='adam',\n",
        "#     metrics=['accuracy']\n",
        "# )"
      ],
      "metadata": {
        "id": "LNOz6UqUHAJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "EPOCHS = 50\n",
        "opt = Adam(lr=lr, decay=lr / (EPOCHS * 0.5))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "Nk5a9wtU9YT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "history = model.fit(aug.flow(x_train, y_train, batch_size =32),\n",
        "                    validation_data = (x_val, y_val), \n",
        "                    epochs=EPOCHS, \n",
        "                    steps_per_epoch=60\n",
        "                   )\n",
        "\n",
        "model.evaluate(x_val,  y_val, verbose=2)"
      ],
      "metadata": {
        "id": "T-ob-YH_PCCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Dh06jU5NH8Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG-16 모델"
      ],
      "metadata": {
        "id": "PxgMOs7eSIIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir):\n",
        "    images = list()\n",
        "    labels = list()\n",
        "    for category in range(NUM_CATEGORIES):\n",
        "        categories = os.path.join(data_dir, str(category))\n",
        "        for img in os.listdir(categories):\n",
        "            img = load_img(os.path.join(categories, img), target_size=(64, 64))\n",
        "            image = img_to_array(img) # 이미지를 넘파이 배열로 변환\n",
        "            images.append(image) \n",
        "            labels.append(category)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "images, labels = load_data(train_path)\n",
        "\n",
        "image_data = np.array(images)\n",
        "image_labels = np.array(labels)"
      ],
      "metadata": {
        "id": "rsOEz3IYGz8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.4)\n",
        "x_train = x_train.astype('float32')/255 \n",
        "x_val = x_val.astype('float32')/255\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
        "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)"
      ],
      "metadata": {
        "id": "jKweMmC8HPK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(64, 64, 3))\n",
        "\n",
        "x= inputs\n",
        "x=layers.Conv2D(64, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(64, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.MaxPooling2D(2)(x)\n",
        "x=layers.Conv2D(128, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(128, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.MaxPooling2D(2)(x)\n",
        "x=layers.Conv2D(256, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(256, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(256, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.MaxPooling2D(2)(x)\n",
        "x=layers.Conv2D(512, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(512, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(512, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.MaxPooling2D(2)(x)\n",
        "x=layers.Conv2D(512, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(512, 3, activation='relu', padding=\"same\")(x)\n",
        "x=layers.Conv2D(512, 3, activation='relu', padding=\"same\")(x)\n",
        "x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
        "x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
        "x = layers.Dense(1000, activation='softmax', name='predictions')(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dense(43, activation='softmax')(x)\n",
        "outputs = x\n",
        "\n",
        "model_1 = keras.Model(inputs, outputs)\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "B-GPEUFzSHw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EPOCHS = 30\n",
        "# lr = 0.001\n",
        "# opt = Adam(lr=lr, decay=lr / (EPOCHS * 0.5))\n",
        "\n",
        "# aug = ImageDataGenerator(\n",
        "#     rotation_range=10,\n",
        "#     zoom_range=0.15,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     shear_range=0.15,\n",
        "#     horizontal_flip=False,\n",
        "#     vertical_flip=False,\n",
        "#     fill_mode=\"nearest\")\n",
        "\n",
        "# model_1.compile(optimizer='adam',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# history_1 = model_1.fit(x_train, y_train, epochs=3, validation_data = (x_val, y_val), steps_per_epoch=60)\n",
        "# model_1.evaluate(x_val,  y_val, verbose=2)"
      ],
      "metadata": {
        "id": "6F_KczP6SFrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "classes = 43\n",
        "batch = 256\n",
        "epochs = 3\n",
        "learning_rate = 0.0001\n",
        "\n",
        "def results(model):\n",
        "  adam = Adam(lr=learning_rate)\n",
        "\n",
        "  model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  start = time()\n",
        "  history = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, validation_split=0.2, shuffle = True, verbose=1)\n",
        "  train_time = time() - start\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  plt.figure(figsize=(12, 12))\n",
        "  plt.subplot(3, 2, 1)\n",
        "  plt.plot(history.history['accuracy'], label = 'train_accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()\n",
        "  plt.subplot(3, 2, 2)\n",
        "  plt.plot(history.history['loss'], label = 'train_loss')\n",
        "  plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  start = time()\n",
        "  test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "  test_time = time() - start\n",
        "  print('\\nTrain time: ', train_time)\n",
        "  print('Test accuracy:', test_acc)\n",
        "  print('Test loss:', test_loss)\n",
        "  print('Test time: ', test_time)"
      ],
      "metadata": {
        "id": "KD-cKAKb529M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "model.add(VGG19(weights='imagenet', include_top=False, input_shape=(64,64,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='sigmoid'))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "results(model)"
      ],
      "metadata": {
        "id": "eCsUpn1O4niz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(history_1.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history_1.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history_1.history['loss'], label='training loss')\n",
        "plt.plot(history_1.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "TVt9YeFKaKjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNet"
      ],
      "metadata": {
        "id": "fSVPEb34LoXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, GlobalAvgPool2D, AvgPool2D, MaxPool2D, Flatten, Dense, Softmax, DepthwiseConv2D, BatchNormalization, ReLU\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=2, input_shape=(64, 64, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(64, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(128, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(128, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(256, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(256, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(512, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "for i in range(5):\n",
        "    model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv2D(512, (1, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(1024, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Conv2D(1024, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(ReLU())\n",
        "\n",
        "# model.add(AvgPool2D((7, 7)))\n",
        "model.add(GlobalAvgPool2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(43))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Softmax())\n",
        "\n",
        "EPOCHS =30\n",
        "\n",
        "lr = 0.001\n",
        "opt = Adam(lr=lr, decay=lr / (EPOCHS * 0.5))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VpemWSTILwW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(aug.flow(x_train, y_train, batch_size =32), epochs=5, validation_data = (x_val, y_val), steps_per_epoch=60)\n",
        "# model_1.evaluate(x_val,  y_val, verbose=2)\n",
        "\n",
        "# plt.figure(0)\n",
        "# plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "# plt.title('Accuracy')\n",
        "# plt.xlabel('epochs')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure(1)\n",
        "# plt.plot(history.history['loss'], label='training loss')\n",
        "# plt.plot(history.history['val_loss'], label='val loss')\n",
        "# plt.title('Loss')\n",
        "# plt.xlabel('epochs')\n",
        "# plt.ylabel('loss')\n",
        "# plt.legend()"
      ],
      "metadata": {
        "id": "dl8BcofMN2Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, validation_data = (x_val, y_val), steps_per_epoch=60)\n",
        "model.evaluate(x_val,  y_val, verbose=2)\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "dEkfXqMuuyxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터 통일하지 않고 진행했을때\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, GlobalAvgPool2D, AvgPool2D, MaxPool2D, Flatten, Dense, Softmax, DepthwiseConv2D, BatchNormalization, ReLU\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=2, input_shape=(64, 64, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(64, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(128, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(128, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(256, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(256, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(512, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "for i in range(5):\n",
        "    model.add(DepthwiseConv2D((3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv2D(512, (1, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(1024, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(DepthwiseConv2D((3, 3), strides=2, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "model.add(Conv2D(1024, (1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ReLU())\n",
        "# model.add(AvgPool2D((7, 7)))\n",
        "model.add(GlobalAvgPool2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.add(Softmax())\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "aug = image.ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "testDataGen = image.ImageDataGenerator(\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "0w8JF9QQTlfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataGen = image.ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "testDataGen = image.ImageDataGenerator(\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "y80pbT1UhZK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataGenerator = trainDataGen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='/content/',\n",
        "    x_col='Path',\n",
        "    y_col='ClassId',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n",
        "testDataGenerator = testDataGen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory='/content/',\n",
        "    x_col='Path',\n",
        "    y_col='ClassId',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n",
        "history = model.fit_generator(\n",
        "    trainDataGenerator,\n",
        "    steps_per_epoch=500,\n",
        "    epochs=3,\n",
        "    validation_data=testDataGenerator,\n",
        "#     validation_steps=800,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "ZNSSoT-dh5AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(aug.flow(x_train, y_train, batch_size =64), epochs=16, validation_data = (x_val, y_val), steps_per_epoch=500)\n",
        "model.evaluate(x_val,  y_val, verbose=2)"
      ],
      "metadata": {
        "id": "SdY4OI9cZYNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_7MeEZOyh3TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "dcOHWimK8wQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "hxXkgMceIDIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test = pd.read_csv('/content/Test.csv')\n",
        "test_labels = Y_test[\"ClassId\"].values\n",
        "test_images = Y_test[\"Path\"].values\n",
        "\n",
        "a =  pathlib.Path('/content/')\n",
        "\n",
        "output = list()\n",
        "for img in test_images:\n",
        "    image = load_img(os.path.join(a, img), target_size=(32, 32))\n",
        "    output.append(np.array(image))\n",
        "\n",
        "X_test=np.array(output)\n",
        "y_prob = model.predict(X_test) # 가장 정확도 높은 모델로 수정\n",
        "pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "#테스트 데이터의 정확도\n",
        "print('Test Data accuracy: ',accuracy_score(test_labels, pred)*100)"
      ],
      "metadata": {
        "id": "8TZ12S8jIJ-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "labels = test_df[\"ClassId\"].values\n",
        "print(classification_report(labels, pred))"
      ],
      "metadata": {
        "id": "EUNZv9XlIXfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (13, 13))\n",
        "\n",
        "start_index = 0\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    prediction = pred[start_index + i]\n",
        "    actual = test_labels[start_index + i]\n",
        "    col = 'g'\n",
        "    if prediction != actual:\n",
        "        col = 'r'\n",
        "    plt.xlabel('Actual={} || Pred={}'.format(actual, prediction), color = col)\n",
        "    plt.imshow(X_test[start_index + i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FQMamNGEIU8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 잘 안된 것 시각화\n",
        "# rows = 3\n",
        "# cols = 4\n",
        "# fig, axs = plt.subplots(rows, cols, sharex=True, sharey=True, figsize=(25, 8))\n",
        "# visualize = train_df.sample(rows*cols)\n",
        "\n",
        "# analys_df_copy = analys_df[analys_df['prediction_type'] == 'Wrong'].copy()\n",
        "# analys_df_copy = analys_df_copy.sample(frac=1)\n",
        "\n",
        "# idx = 0\n",
        "# for i in range(rows):\n",
        "#     for j in range(cols):\n",
        "#         img = cv2.imread(analys_df_copy.iloc[idx]['image'])\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#         img = cv2.resize(img, (100, 100))\n",
        "        \n",
        "#         gt = analys_df_copy.iloc[idx]['gt']\n",
        "#         pred = analys_df_copy.iloc[idx]['prediction']\n",
        "        \n",
        "#         axs[i,j].imshow(img)\n",
        "#         axs[i,j].set_title('Predicted: {}\\nGround truth {}'.format(labels[pred], labels[gt]), fontsize=14)\n",
        "#         axs[i,j].get_xaxis().set_visible(False)\n",
        "#         axs[i,j].get_yaxis().set_visible(False)\n",
        "#         idx += 1\n",
        "        \n",
        "# fig.suptitle(\"Wrong prediction\", fontsize=30, y=2.1, x=0.515);\n",
        "# plt.subplots_adjust(left=None, bottom=None, right=0.9, top=1.9, wspace=None, hspace=None)"
      ],
      "metadata": {
        "id": "MhlTl15CIVXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bIP___u6aoS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}